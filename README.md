## Aggregate the Link-Lives datasets into one

email: crf764@econ.ku.dk

### 'finaldata.csv' is my final file.

#### 1. Guide to creating an aggregated dataset

1. You need a program that can execute Jupyter notebook files with a python kernel (e.g. Jupyter Lab, Visual Studio Code), as well as the Anaconda package.
2. Open setfactory.ipynb
3. Ensure that you have demografi.py in the same folder as the notebook
4. Ensure that you have the .csv files needed and change the path in the second code cell of the notebook, if necessary, to the path on your computer
5. Run the whole notebook, at once or cell by cell.  

6. (optional) Add any additional .csv paths and corresponding names to the second code cell in the notebook.(.csv files MUST be in the order written below in section 2). 
    Then run the notebook again to produce a new .csv containing the additional sources.    
    






#### 2. Source guide (names and corresponding numbers)

The enumeration and the order is important for correctly cleaning and creating datasets, the names can be changed. 

11-16 are currently unavailable.

t refers to transcribed sources, s to standardized sources.

0: census1787t/s 

1: census1801t/s  

2: census1834t/s 

3: census1840t/s 

4: census1845t/s 

5: census1850t/s

6: census1860t/s

7: census1880t/s

8: census1885t/s

9: census1901t/s

10: CBPt/s - Transcribed Copenhagen Burial Protocols 1861-1911

11: PR Burial

12: PR Baptism

13: PR Marriage

14: PR Confirmation

15: PR Departure

16: PR Arrival

11-16: Currently unavailable Parish Records
